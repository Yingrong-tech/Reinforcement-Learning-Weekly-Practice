{"cells":[{"cell_type":"markdown","id":"e35ecbb1","metadata":{"id":"e35ecbb1"},"source":["# Week 1: 43008 Reinforcement Learning\n","\n","## PART-B: Hands-on OpenAI Gym Tasks\n","\n","In this part, we'll perform some hands-on activites using OpenAI Gym!.\n","\n","#### Part 1: Create a OpenAI Gym Environment for Frozen Lake\n","\n","\n","\n","#### Part 2: Execute some operation and rendering\n"]},{"cell_type":"markdown","id":"243a0f6a","metadata":{"id":"243a0f6a"},"source":["## Part 1: Create a Fronzen Lake Environment\n","\n","You may follow the below steps:\n","\n","1.   Installaton\n","2.   Importing OpenAI Gym\n","4.   Creating an Instance of an Environment\n","5.   Interacting with the Environment Instance\n","6.   Rendering"]},{"cell_type":"markdown","source":["### Step 1: Installation\n","\n","`!pip install gym`\n","\n","Downgrade numpy library for compatibility\n","\n","`!pip install numpy==1.23.5`\n","\n","**Rendering dependencies <-- Required for Google Colab**\n","\n","`!pip install gym pyvirtualdisplay > /dev/null 2>&1`\n","\n","`!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1`\n","\n","`!apt-get install xvfb `"],"metadata":{"id":"gBnxBdKudRLw"},"id":"gBnxBdKudRLw"},{"cell_type":"code","source":["# Install OpenAI Gym\n","# WRITE YOUR CODE HERE\n"],"metadata":{"id":"YR3bbKfWdvK6"},"id":"YR3bbKfWdvK6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Rendering dependencies <-- Required for Google Colab\n","# WRITE YOUR CODE HERE\n"],"metadata":{"id":"fHYHDSiFdxBf"},"id":"fHYHDSiFdxBf","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 2: Importing OpenAI Gym and other packages\n","\n","**Import OpenAi Gym**\n","`import gym`\n","\n","**import other required libraries/packages**\n","\n","`from gym.wrappers.record_video import RecordVideo`\n","\n","`import glob`\n","\n","`import io`\n","\n","`import base64`\n","\n","`from IPython.display import HTML`\n","\n","`from IPython import display as ipythondisplay`"],"metadata":{"id":"9IRwVntnd1JA"},"id":"9IRwVntnd1JA"},{"cell_type":"code","source":["# Import OpenAi Gym\n","import gym\n","\n","# import other required libraries/packages\n","from gym.wrappers.record_video import RecordVideo\n","import glob\n","import io\n","import base64\n","from IPython.display import HTML\n","from IPython import display as ipythondisplay"],"metadata":{"id":"cmmVcRDkeR93"},"id":"cmmVcRDkeR93","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Helper Functions for rendering on Google Colab (Don't Delete!)"],"metadata":{"id":"d1FI5J09eq6Y"},"id":"d1FI5J09eq6Y"},{"cell_type":"code","source":["from IPython.display import HTML\n","from pyvirtualdisplay import Display\n","from IPython import display as ipythondisplay\n","\n","display = Display(visible=0, size=(1400, 900))\n","display.start()\n","\n","\n","# Utility functions to enable video recording of gym environment and displaying it\n","# To enable video, just do \"env = wrap_env(env)\"\n","\n","# Function to Show video after rendering\n","def show_video():\n","  mp4list = glob.glob('video/*.mp4')\n","  if len(mp4list) > 0:\n","    mp4 = mp4list[0]\n","    video = io.open(mp4, 'r+b').read()\n","    encoded = base64.b64encode(video)\n","    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","  else:\n","    print(\"Could not find video\")\n","\n","# Warpper for Environment to record the video\n","def wrap_env(env):\n","  env = RecordVideo(env, './video',  episode_trigger = lambda episode_number: True)\n","  return env"],"metadata":{"id":"mA5sIJZAepM4"},"id":"mA5sIJZAepM4","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 3: Creating an instance of Frozen Lake Environment\n","\n","`env = wrap_env(gym.make('FrozenLake-v1', new_step_api=True))`"],"metadata":{"id":"rB5gjBzweTUX"},"id":"rB5gjBzweTUX"},{"cell_type":"code","source":["env = # WRITE YOUR CODE HERE\n","\n","# Display info about the environment\n","print(\"Action space: \", ) # <-- COMPLETE THE CODE\n","print(\"Observation space: \", ) # <-- COMPLETE THE CODE"],"metadata":{"id":"T6irPlq3ejfH"},"id":"T6irPlq3ejfH","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 2: Execute some operation and rendering"],"metadata":{"id":"kjBoIpYJ2WR5"},"id":"kjBoIpYJ2WR5"},{"cell_type":"markdown","source":["### Step 4: Interacting with the Environment Instance\n","\n","Hint: use the below functions\n","\n","- `env.reset()`\n","- `env.action_space.sample()`\n","- `env.step(action)`\n","- `env.render()`\n","- `env.close()`"],"metadata":{"id":"Y1Xa6xZUe5zG"},"id":"Y1Xa6xZUe5zG"},{"cell_type":"code","source":["env.reset()  # Reset the environment to the initial state\n","terminated = False  # Flag to indicate if the episode is finished\n","step = 0\n","env.render()\n","\n","while not terminated:\n","    action = env.action_space.sample()  # Choose a random action\n","    observation, reward, terminated, info = env.step(action)  # Take a step\n","\n","    # Perform your own computations or actions here\n","    # Print each step results\n","    print(\"---- Step: \", step, \" ----\")\n","    print(\"Action : \", ) #<-- COMPLETE THE CODE\n","    print(\"Observation :\", ) #<-- COMPLETE THE CODE\n","    print(\"Reward : \", ) #<-- COMPLETE THE CODE\n","    print(\"Terminated? :\", ) #<-- COMPLETE THE CODE\n","    print(\"Info :\", , '\\n') #<-- COMPLETE THE CODE\n","     # increase the step count, #<-- COMPLETE THE CODE\n","\n","env.close()  # Close the environment"],"metadata":{"id":"cKHbrrkve49G"},"id":"cKHbrrkve49G","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show the recorded video of the Environment\n","show_video()"],"metadata":{"id":"XMgFUixdf-m9"},"id":"XMgFUixdf-m9","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"a08f6906","metadata":{"id":"a08f6906"},"source":["In this tutorial, you learned how to use Python for RL and implemented a simple RL problem using the Q-learning algorithm. Now, you should be familiar with RL concepts and ready to tackle more complex problems."]}],"metadata":{"kernelspec":{"display_name":"apple","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"provenance":[],"collapsed_sections":["d1FI5J09eq6Y"]}},"nbformat":4,"nbformat_minor":5}